<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Posts | 九原山</title><meta name=keywords content><meta name=description content="Posts - 九原山"><meta name=author content><link rel=canonical href=https://ninehills.tech/posts/><link crossorigin=anonymous href=/assets/css/stylesheet.min.c88963fe2d79462000fd0fb1b3737783c32855d340583e4523343f8735c787f0.css integrity="sha256-yIlj/i15RiAA/Q+xs3N3g8MoVdNAWD5FIzQ/hzXHh/A=" rel="preload stylesheet" as=style><link rel=icon href=https://ninehills.tech/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://ninehills.tech/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://ninehills.tech/favicon-32x32.png><link rel=apple-touch-icon href=https://ninehills.tech/apple-touch-icon.png><link rel=mask-icon href=https://ninehills.tech/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.112.6"><link rel=alternate type=application/rss+xml href=https://ninehills.tech/posts/index.xml><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Posts"><meta property="og:description" content><meta property="og:type" content="website"><meta property="og:url" content="https://ninehills.tech/posts/"><meta name=twitter:card content="summary"><meta name=twitter:title content="Posts"><meta name=twitter:description content><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://ninehills.tech/posts/"}]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://ninehills.tech/ accesskey=h title="九原山 (Alt + H)">九原山</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu></ul></nav></header><main class=main><header class=page-header><h1>Posts</h1></header><article class=post-entry><header class=entry-header><h2>大语言模型（LLM）微调技术笔记</h2></header><section class=entry-content><p>注：本文大段摘抄自 1
图1：大模型进化树2
0x00 大模型微调 在预训练后，大模型可以获得解决各种任务的通用能力。然而，越来越多的研究表明，大语言模型的能力可以根据特定目标进一步调整。
这就是微调技术，目前主要有两种微调大模型的方法1：
指令微调，目标是增强（或解锁）大语言模型的能力。 对齐微调，目标是将大语言模型的行为与人类的价值观或偏好对齐。 在 OpenAI 发布的 ChatGPT 中，就主要应用了微调技术3，从而获得了惊艳全世界的效果。
图2：InstuctGPT 原理
0x10 指令微调 ( Instruction Tuning) 本质上，指令微调是在自然语言格式的实例集合上微调预训练后的大语言模型的方法。这种方法与有监督微调和多任务提示训练密切相关。为了进行指令微调，我们首先需要收集或构造指令格式的实例。然后，我们使用这些格式化的实例以有监督的方式微调大语言模型（例如，使用序列到序列的损失进行训练）。指令微调后，大语言模型展现出泛化到未见过任务的卓越能力 ，即使在多语言场景下也能有不错表现。
0x11 格式化实例构造（微调数据集） 通常情况下，一个指令格式化的实例包括一个任务描述（被称为指令 instruction)、一个输入输出对以及少量示例（可选）。
数据集一般用两种方法产出：
图3：实例格式化和两种构造指令格式实例的示意图。1
格式化已有数据集。将传统的NLP数据集格式调整后，用于指令微调。 为降低人工格式化成本，可以通过 ChatGPT 生成 Instruciton。典型 Prompt：“请你为这段内容生成一个合理的问题” 人工标注数据集。为获得更好的人类对齐效果，OpenAI 建议使用人工标注数据集。 为降低人工标注成本，目前很多数据集由 ChatGPT 生成，包括用户分享的 ChatGPT 对话历史（如 ShareGPT）或者使用 ChatGPT生成的数据集。 数据集也分为通用任务的数据集以及专用数据集，前者目前有大量开源数据集可供使用，后者则针对某个具体领域，可以自行构建。此外引入多样化的数据集（包括引入 CoT思维链等）可以有效的提升模型性能。
目前通用的中文微调数据集：
数据集 内容 Stanford Alpaca (Chinese) Alpaca 数据集中文翻译（ChatGPT 辅助翻译） BELLE BELLE 项目的中文数据集（ChatGPT 生成） GuanacoDataset Guannaco 模型的对话数据集 WebQA(zh) 中文网络问答 pCLUE 基于提示的大规模预训练数据集，用于多任务学习和零样本学习 其余中文数据集可以参见：
https://github.com/CVI-SZU/Linly/blob/main/instructions/README.md https://github.com/hiyouga/ChatGLM-Efficient-Tuning/blob/main/data/README.md 0x12 数据集格式示例 典型的数据集格式：{"instruction": "", "input": "", "output": ""}， 如果要微调已经经过指令微调的模型，那么微调数据集的格式应该保持不变以获得最佳效果，格式包括分隔符、代码标签等。...</p></section><footer class=entry-footer><span title='2023-05-12 06:49:26 +0000 UTC'>May 12, 2023</span></footer><a class=entry-link aria-label="post link to 大语言模型（LLM）微调技术笔记" href=https://ninehills.tech/posts/ninehills-ninehills.github.io-1707040547-post-92/></a></article><article class=post-entry><header class=entry-header><h2>小工具 p2pfile 可以快速的用于内网大文件分发</h2></header><section class=entry-content><p>p2pfile - Simple P2P file distribution CLI https://github.com/ninehills/p2pfile
背景 应用场景 所有节点网络联通的环境下的文件分布式分发。 私有网络环境，和互联网隔离。 无文件加密传输需求 设计限制 DHT 网络中在这种环境下意义不大，所以不使用 DHT 网络，而是使用自带的集中 Tracker 在第一个测试版本使用纯 DHT 网络，发现其交换效率低于 Tracker. 不需要 Daemon 常驻进程，只需要单个二进制文件。 无加密设计 只支持单个文件分发，不支持文件夹分发。 不支持 IPv6。 设计目标 提供私有网络环境下的文件分布式分发。 提供最简化的使用方法，一条命令。 命令行设计 做种：
Creates and seeds a torrent from file paths. Usage: p2pfile serve &lt;FILE_PATH> Usage: p2pfile serve [flags] Flags: --tracker-ip string Set tracker ip. (default: default route ip) --tracker-port int Set tracker port. (default: random port in port-range, See --port-range) --tracker-port-range string Set tracker random port range....</p></section><footer class=entry-footer><span title='2022-01-29 14:22:52 +0000 UTC'>January 29, 2022</span></footer><a class=entry-link aria-label="post link to 小工具 p2pfile 可以快速的用于内网大文件分发" href=https://ninehills.tech/posts/ninehills-ninehills.github.io-1118234175-post-88/></a></article><article class=post-entry><header class=entry-header><h2>《植物大战僵尸》PC/Mac版存档修改</h2></header><section class=entry-content><p>0x00 为啥想玩这个？ LP：我想玩植物大战僵尸。 我：iOS上只有一个氪金的2代，我给你买原版的。英文可以接受不？ LP：你小看我了！ 我：那马上好。
Steam上下单《Plants vs. Zombies: Game of the Year》。
LP：我不想从第一关开始玩，都玩腻了，我要直接玩无尽模式。 我：我来研究下。
搜了一圈，发现Mac上没有修改器，只好自己去修改存档文件。
主要参考：https://plantsvszombies.fandom.com/wiki/User_file_format
0x01 找到存档文件 wiki上说存档文件在./Application Support/PopCap/PlantsVsZombiesMac/userdata下，但是Steam版本的该路径只有userdata_backup，真正的userdata通过find命令可以找到，在./Application Support/Steam/userdata/124091088/3590/remote/中（其中124091088是你的steam id）。
找到user1.dat即为存档文件（存在多个用户找对应的user${n}.dat, 用户序号可以在users.dat中找到
然后先备份存档文件（所有操作前请先备份）
0x02 HEX工具 在Mac上直接用vim即可，通过vim user1.dat可以打开文件。然后输入:%!xxd可以将其显示为HEX格式，之后便可以进行修改。修改完成后，一定要先:%!xxd -r转换为二进制文件，然后在:wq保存。（注意修改时游戏需要关闭或者使用不同的用户）
0x03 修改存档 参考 https://plantsvszombies.fandom.com/wiki/User_file_format 修改存档即可。存档格式：
存档文件是小端模式，也就是比如四个字节的0x12345678，实际上存放是0x78563412。 存档中的所有变量都是四个字节的整数 如果要实现解锁无尽模式，那么需要修改的：
修改 Adventure Mode的完成次数，改成 >= 2，修改后解锁 Mini-Game 等模式。 修改生存模式各个子模式的完成度，全部设置为完成（大于给定的值，我统一设成0x0b），从而直接解锁最终的无尽模式。 最终效果
启动游戏</p></section><footer class=entry-footer><span title='2020-05-03 13:33:35 +0000 UTC'>May 3, 2020</span></footer><a class=entry-link aria-label="post link to 《植物大战僵尸》PC/Mac版存档修改" href=https://ninehills.tech/posts/ninehills-ninehills.github.io-611415468-post-78/></a></article><article class=post-entry><header class=entry-header><h2>Kubernetes 基于 Namespace 的物理队列实现</h2></header><section class=entry-content><p>Kubernetes 基于 Namespace 的物理队列实现 作者：swulling+pub@gmail.com
摘要：Kubernetes 实现基于 Namespace 的物理队列，即Namespace下的Pod和Node的强绑定
0x00 背景 Kuberntes 目前在实际业务部署时，有两个流派：一派推崇小集群，一个或数个业务共享小集群，全公司有数百上千个小集群组成；另一派推崇大集群，每个AZ（可用区）一个或数个大集群，各个业务通过Namespace的方式进行隔离。
两者各有优劣，但是从资源利用率提升和维护成本的角度，大集群的优势更加突出。但同时大集群也带来相当多的安全、可用性、性能的挑战和维护管理成本。
本文属于Kubernetes多租户大集群实践的一部分，用来解决多租户场景下，如何实现传统的物理队列隔离。
物理队列并不是一个通用的业界名词，它来源于一种集群资源管理模型，该模型简化下如下：
逻辑队列（Logical Queue）：逻辑队列是虚拟资源分配的最小单元，将虚拟资源配额（Quota）配置在逻辑队列上（如CPU 200 标准核、内存 800GB等） 逻辑队列对应Kubernetes的Namespace概念。参考Resource Quotas 不同的逻辑队列之间可以设置Qos优先级，实现优先级调度。参考Limit Priority Class consumption by default可以限制每个Namespace下Pod的优先级选择 配额分两种：Requests（提供保障的资源）和Limits（资源的最大限制），其中仅Requests才能算Quota，Limits 由管理员视情况选择 物理队列（Physical Queue）：物理队列对应底层物理机资源，同一台物理机仅能从属于同一个物理队列。物理队列的资源总额就是其下物理机可提供的资源的总和。 物理队列当前在Kubernetes下缺乏概念映射 逻辑队列和物理队列是多对多绑定的关系，即同一个逻辑队列可以跨多个物理队列。 逻辑队列的配额总和 / 物理队列的资源总和 = 全局超售比 租户：租户可以绑定多个逻辑队列，对应关系仅影响往对应的Namespace中部署Pod的权限。 资源结构如图所示：
0x01 原理 物理队列实现：
给节点配置Label和Taint，Label用于选择，Taint用于拒绝非该物理队列的Pod部署。 和Namespace的自动绑定的原理：
配置两个Admission Controller: PodNodeSelector和PodTolerationRestriction，参考Admission Controllers 给Namespace增加默认的NodeSelector和Tolerations策略，并自动应用到该 Namespace 下的全部新增 Pod 上，从而自动将Pod绑定到物理队列上。 0x02 配置 测试集群版本：1.16.4, 1.17.0，使用的测试集群为Kind创建 1.18.0 版本的Kind集群创建有问题，后续进行测试
# this config file contains all config fields with comments # NOTE: this is not a particularly useful config file kind: Cluster apiVersion: kind....</p></section><footer class=entry-footer><span title='2020-04-10 04:22:00 +0000 UTC'>April 10, 2020</span></footer><a class=entry-link aria-label="post link to Kubernetes 基于 Namespace 的物理队列实现" href=https://ninehills.tech/posts/ninehills-ninehills.github.io-597686461-post-77/></a></article><article class=post-entry><header class=entry-header><h2>SRE 技术简报 20200310</h2></header><section class=entry-content><p>SRE 技术简报 20200310 前沿进展 0x00. The Future of Containers - What’s Next?
容器技术的未来是什么？作者认为是 MicroVM 以及 Unikernel。但我认为 Unikernel 模型和传统应用变化太大，应该很难落地，而 MicroVM 是目前非常火的 Serverless Container的基础，前景更加广阔。
优秀文章 0x10. The Complete Guide to Kubernetes Logging
Kubernetes 日志相关的方法和实践，维护K8s集群的话，值得参考。
0x11. 调度系统设计精要
2w字长文精解调度系统设计。作者是Draveness，他的一系列文章质量都很高。
开源项目 0x20. Trackman - Execute commands as a workflow.
一个小的命令行工具，可以将多个Shell命令组装成工作流，比较适合复杂业务流程的脚本化工作。
0x21. Open-Sourcing riskquant, a library for quantifying risk
基于The Factor Analysis of Information Risk (FAIR) 框架的风险评估的Python库，支持基于 lognormal 分布或 Modified PERT 分布的风险损失评估，从而指导企业进行风险控制。NetFlix 为此招聘了两名全职的 Risk Engineer 进行风险评估和控制指导。...</p></section><footer class=entry-footer><span title='2020-03-20 02:35:48 +0000 UTC'>March 20, 2020</span></footer><a class=entry-link aria-label="post link to SRE 技术简报 20200310" href=https://ninehills.tech/posts/ninehills-ninehills.github.io-584806966-post-76/></a></article><article class=post-entry><header class=entry-header><h2>游戏 《天命奇御》</h2></header><section class=entry-content><p>《天命奇御》是台湾一家地产商开发的传统武侠游戏，用两周时间花了30个小时通关了主线剧情，从几个方面聊一聊优缺点。
支线剧情和相关互动已经不能用十分丰富来形容，有数百个可以互动和出示的物品，数十个内容丰富的支线任务。此外主线和支线任务的质量都很高，而物品、环境、人物上的很多对话等，表明开发商对古代文化是做了很多的研究。
战斗系统抛弃了传统的回合制战斗模式，使用了固定战斗场景内的即时战斗。如果支线任务尽可能做的话，等级和属性提高的比较快，难度较低。整体战斗系统的创新有，也有一定的趣味，但是并没有太多研究的空间，最大的乐趣可能是战斗外收集各种武学、心法的收集欲望了。
少数的允许后宫结局的武侠游戏，齐人之福可以有4个妹子，其中从刻画上来看都各有特色和性格，也有专属的支线任务链，并不是脸谱化的女性角色。
画面和动作限于成本，比较简单，可以说不是19年的游戏。
用IGN的新评价体系来评价的话，可以给 8分 Great！</p></section><footer class=entry-footer><span title='2020-01-14 04:01:38 +0000 UTC'>January 14, 2020</span></footer><a class=entry-link aria-label="post link to 游戏 《天命奇御》" href=https://ninehills.tech/posts/ninehills-ninehills.github.io-549317418-post-75/></a></article><article class=post-entry><header class=entry-header><h2>SRE 技术简报 20200114</h2></header><section class=entry-content><p>前沿进展 0x00. Aperture: A Non-Cooperative, Client-Side Load Balancing Algorithm
一种无需各个客户端之间进行协作的客户端负载均衡算法，文章见：Deterministic Aperture: A distributed, load balancing algorithm。
优秀文章 0x10. SOSP19’ Ceph 的十年经验总结：文件系统是否适合做分布式文件系统的后端
这篇文章是 SOSP 2019 发的文章，介绍了 Ceph 为何在使用了十多年的本地文件系统之后，又开发了基于裸设备的存储后端 BlueStore，并将默认存储后端切到了基于裸设备 BlueStore。
0x11. Cpython Internals
CPython 源码阅读笔记, 多图展示底层实现细节.
0x12. Intelligent DNS based load balancing at Dropbox
Dropbox 的全球智能DNS负载均衡，讲从地理临近调度演进为延迟最小调度。其中可以看到要做一个全球服务的复杂性，比如需要考虑各地的海底光缆的分布等。
开源项目 0x20. Reducing alert fatigue with GoAlert, Target’s on-call scheduling and notification platform
老牌开源监控产品 Sensu 全新开发的告警管理系统Sensu Go。业界告警系统重监控，监控后触发告警的管理较少，Sensu Go有很多理念都比较契合实际需求，如Silence、Ack/Close机制等。
0x21. Chaos Mesh —— 让应用跟混沌在 Kubernetes 上共舞...</p></section><footer class=entry-footer><span title='2020-01-14 03:49:09 +0000 UTC'>January 14, 2020</span></footer><a class=entry-link aria-label="post link to SRE 技术简报 20200114" href=https://ninehills.tech/posts/ninehills-ninehills.github.io-549314561-post-74/></a></article><article class=post-entry><header class=entry-header><h2>SRE 技术简报 20191222</h2></header><section class=entry-content><p>SRE 技术简报 20191222 前沿进展 0x00. Poetry - Python dependency management and packaging made easy.
Python 的依赖管理一直被人诟病，Poetry 类似于 PHP 的 composer 或者 Ruby 的 cargo，值得尝试。
0x01. Hubble - Network, Service & Security Observability for Kubernetes
可以理解为是基于 eBPF 和 Ciium 的看板，可以看K8s的服务依赖图以及根据eBPF监控的实时网络性能。
优秀文章 0x10. The Art of SLOs Workshop
Google 提供的 SLO 相关的 Workshop，可以配合在 Coursera的免费课程 一起动手实践，其中使用了真实的各种服务模型进行 SLO 的抽象。
0x11. Shrinking the time to mitigate production incidents - CRE life lessons
通过灾难演练等方法，提高工程师处理故障事件的效率。做这种事情的前提是故障模式非常复杂，复杂故障依然需要工程师介入处理。随着系统越来越成熟，故障的绝对数量肯定是越来越少，那么如何保证团队里所有Oncall的工程师（特别是新工程师）都有足够的能力处理突发故障，就需要从故障的上层管理、组织机制、日常演练等方式入手。
0x12. Journey into Observability: Reading material...</p></section><footer class=entry-footer><span title='2019-12-22 05:18:04 +0000 UTC'>December 22, 2019</span></footer><a class=entry-link aria-label="post link to SRE 技术简报 20191222" href=https://ninehills.tech/posts/ninehills-ninehills.github.io-541409285-post-73/></a></article><article class=post-entry><header class=entry-header><h2>SRE 技术简报 20191127</h2></header><section class=entry-content><p>前沿进展 KubeCon North America 2019 ( 11.18 - 11.21)
KubeCon North America 2019 上周在圣地亚哥举办，目前各个Topic的材料已经基本上传完毕，但是还没有上传视频，感兴趣可以关注下。
没有参加过KubeCon的小伙伴可以关注 @drkellyannfitz 的现场记录：
KubeCon North America 2019 Day0 KubeCon North America 2019 Day1 KubeCon North America 2019 Day2 KubeCon North America 2019 Day3 优秀文章 Measuring Production-Readiness Using Qualification Gates
文件存储服务的指标设定的一个实践，通过不间断的测量并配置不同级别的“质量门”，从而使产品达到生产环境要求的质量水平。
The Configuration Complexity Curse
如果厌烦去编写复杂的 YAML 配置，可以看一下这篇文章提出的CUE，它是一种DCL（Data Configuration Language），CUE 想去解决复杂系统带来的复杂配置的难题。值得一提的是，作者之一 @mpvl_ 曾经在Google负责 borgcfg 的维护。
Debugging network stalls on Kubernetes
Github 技术团队定位 K8s 丢包问题的全过程记录，知识点包括 软中断、NAPI、ksoftirqd、内核调试、进程调试等，十分硬核。
携程容器偶发性超时问题案例分析 Part1 Part2...</p></section><footer class=entry-footer><span title='2019-11-27 06:39:00 +0000 UTC'>November 27, 2019</span></footer><a class=entry-link aria-label="post link to SRE 技术简报 20191127" href=https://ninehills.tech/posts/ninehills-ninehills.github.io-529148480-post-72/></a></article><article class=post-entry><header class=entry-header><h2>SREcon18 Americas 我的推荐清单</h2></header><section class=entry-content><p>SREcon18 Americas 最近放出了视频资料，我整理后，觉得值得看的 Talk 如下：
听力不好的同学（比如我），推荐打开 Youtube 自动生成的英文字幕。
部分主题没有被列入，选题和推荐指数纯属个人口味偏好，没有任何原因。 很多我都还来得及看，只是匆匆扫了几眼，难免有错误和疏漏，欢迎回复指出。
1. [Workshop] Containers from Scratch ⭐️⭐️⭐️⭐️ Workshop 是动手环节，这个主题是让你从头实现容器，对理解容器的原理很有帮助。
详细的动手步骤，请参考 https://github.com/Fewbytes/rubber-docker 动手前，可以先读下PPT: Linux Primitives 2. [Workshop] How to Build a Distributed System in 3 Hours ⭐️⭐️⭐️ 这个 Workshop 来自 Google，让你在三小时内设计一个 N+2 的多地域分布式系统，难度系数很高。建议学过 MIT 6.824 后再来看这个。
3. [Workshop] Ansible for SRE Teams ⭐️⭐️⭐️ 就是一个 Ansible 实战指南，对 Ansible 感兴趣的可以了解下：https://github.com/Eronarn/deploying-applications-with-ansible。
从我个人的角度，我觉得中小规模的公司，使用 Ansible 自动化是一个相当不错的选择。
4. [Workshop]Tech Writing 101 for SREs ⭐️⭐️ 如何写技术文章，如故障报告、文档之类，参考 https://lisafc.github.io/tw101-reading/ ，不过这种文章得翻译下才行。
5. [Workshop]Chaos Engineering Bootcamp ⭐️⭐️ Netflix 的 Chaos Engineering 也算是一个招牌了，就和 Baidu 的 AIOps 一样，有兴趣的可以看看。...</p></section><footer class=entry-footer><span title='2018-06-02 04:54:54 +0000 UTC'>June 2, 2018</span></footer><a class=entry-link aria-label="post link to SREcon18 Americas 我的推荐清单" href=https://ninehills.tech/posts/ninehills-ninehills.github.io-328713565-post-63/></a></article><footer class=page-footer><nav class=pagination><a class=next href=https://ninehills.tech/posts/page/2/>Next Page »</a></nav></footer></main><footer class=footer><span>&copy; 2023 <a href=https://ninehills.tech/>九原山</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>